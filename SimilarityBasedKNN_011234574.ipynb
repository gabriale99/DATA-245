{"cells":[{"cell_type":"markdown","metadata":{"id":"1MXQcqQR-eI_"},"source":["**1. (15%) Chapter 5, exercise 2**\n","\n","---\n","\n","**a. What target level would a nearest neighbor model using Euclidean distance return for the following email: “machine learning for free”?**\n","\n","<pre>\n","           MONEY      FREE       FOR      GAMBLING     FUN      MACHINE    LEARNING\n","ID | Euclidean distance\n","1  | sqrt((3 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 0)<sup>2</sup> + (0 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 1)<sup>2</sup>) = 3.606 (3 sig. fig.)\n","2  | sqrt((1 - 0)<sup>2</sup> + (2 - 1)<sup>2</sup> + (1 - 1)<sup>2</sup> + (1 - 0)<sup>2</sup> + (1 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 1)<sup>2</sup>) = 2.449 (3 sig. fig.)\n","3  | sqrt((0 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (1 - 1)<sup>2</sup> + (1 - 0)<sup>2</sup> + (1 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 1)<sup>2</sup>) = 2.236 (3 sig. fig.)\n","4  | sqrt((0 - 0)<sup>2</sup> + (0 - 1)<sup>2</sup> + (1 - 1)<sup>2</sup> + (0 - 0)<sup>2</sup> + (3 - 0)<sup>2</sup> + (1 - 1)<sup>2</sup> + (1 - 1)<sup>2</sup>) = 3.162 (3 sig. fig.)\n","5  | sqrt((0 - 0)<sup>2</sup> + (1 - 1)<sup>2</sup> + (0 - 1)<sup>2</sup> + (0 - 0)<sup>2</sup> + (0 - 0)<sup>2</sup> + (1 - 1)<sup>2</sup> + (1 - 1)<sup>2</sup>) = 1\n","</pre>\n","\n","Target level **false** is returned using Euclidean distance.\n","\n","---\n","\n","**b. What target level would a k-NN model with k = 3 and using Euclidean distance return for the same query?**\n","\n","From the above calculation, the nearest neighbors are ID 5, 3, 2 in ascending order. In these instanecs, 2 of them have target level equals to true while one equals to false. Consequently, the prediction will take the majority of the results and return target level = <b>true</b>.\n","\n","---\n","\n","**c. What target level would a weighted k-NN model with k = 5 and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query, return for the query?**\n","\n","<pre>\n","           MONEY      FREE       FOR      GAMBLING     FUN      MACHINE    LEARNING\n","ID | weighted k-NN with k = 5 and euclidean distance\n","1  | 1 / (3.606)<sup>2</sup> = 0.0769 (3 sig. fig.)\n","2  | 1 / (2.449)<sup>2</sup> = 0.167 (3 sig. fig.)\n","3  | 1 / (2.236)<sup>2</sup> = 0.200 (3 sig. fig.)\n","4  | 1 / (3.162)<sup>2</sup> = 0.100 (3 sig. fig.)\n","5  | 1 / (1)<sup>2</sup> = 1\n","</pre>\n","\n","The weighted model for SPAM = true returns \n","\n","0.0769 + 0.167 + 0.200 = 0.444 (3 sig. fig.), \n","\n","while for SPAM = false returns \n","\n","1 + 0.100 = 1.1  (3 sig. fig.). \n","\n","Because the target level false returns a higher value, the model picks it as the prediction: \n","\n","the query is predicted to be **SPAM = false**.\n","\n","---\n","\n","**d. What target level would a k-NN model with k = 3 and using Manhattan distance return for the same query?**\n","\n","<pre>\n","         MONEY        FREE         FOR       GAMBLING         FUN        MACHINE     LEARNING\n","ID | Manhattan distance\n","1  | abs(3 - 0) + abs(0 - 1) + abs(0 - 1) + abs(0 - 0) + abs(0 - 0) + abs(0 - 1) + abs(0 - 1) = 7\n","2  | abs(1 - 0) + abs(2 - 1) + abs(1 - 1) + abs(1 - 0) + abs(1 - 0) + abs(0 - 1) + abs(0 - 1) = 6\n","3  | abs(0 - 0) + abs(0 - 1) + abs(1 - 1) + abs(1 - 0) + abs(1 - 0) + abs(0 - 1) + abs(0 - 1) = 5\n","4  | abs(0 - 0) + abs(0 - 1) + abs(1 - 1) + abs(0 - 0) + abs(3 - 0) + abs(1 - 1) + abs(1 - 1) = 4\n","5  | abs(0 - 0) + abs(1 - 1) + abs(0 - 1) + abs(0 - 0) + abs(0 - 0) + abs(1 - 1) + abs(1 - 1) = 1\n","</pre>\n","\n","The closest neighbors from the above model returns ID 5, 4 and 3 in ascending order. The majority target level in this groups is false. Therefore, the prediction is **SPAM = false**.\n","\n","---\n","\n","**e. There are a lot of zero entries in the spam bag-of-words dataset. This is indicative of sparse data and is typical for text analytics. Cosine similarity is often a good choice when dealing with sparse non-binary data. What target level would a 3-NN model using cosine similarity return for the query?**\n","\n","\n","<pre>\n","sum of square roots of query = sqrt(0<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> = sqrt(4) = 2\n","\n","                MONEY       FREE      FOR    GAMBLING     FUN     MACHINE   LEARNING\n","ID | Cosine similarity\n","1  | nominator: (3 * 0) + (0 * 1) + (0 * 1) + (0 * 0) + (0 * 0) + (0 * 1) + (0 * 1) = 0\n","   | denominator: sqrt(3<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup>) * 2 = sqrt(9) * 2 = 3 * 2 = 6\n","   | <b>cos(id = 1, query) = 0 / 6 = 0</b>\n","   |\n","2  | nominator: (1 * 0) + (2 * 1) + (1 * 1) + (1 * 0) + (1 * 0) + (0 * 1) + (0 * 1) = 3\n","   | denominator: sqrt(1<sup>2</sup> + 2<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup>) * 2 = sqrt(8) * 2 = 2.828 * 2 = 5.657 (3 sig. fig.)\n","   | <b>cos(id = 2, query) = 3 / 5.292 = 0.530 (3 sig. fig.)</b>\n","   |\n","3  | nominator: (0 * 0) + (0 * 1) + (1 * 1) + (1 * 0) + (1 * 0) + (0 * 1) + (0 * 1) = 1\n","   | denominator: sqrt(0<sup>2</sup> + 0<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup>) * 2 = sqrt(3) * 2 = 1.732 * 2 = 3.464 (3 sig. fig.)\n","   | <b>cos(id = 3, query) = 1 / 3.464 = 0.289 (3 sig. fig.)</b>\n","   |\n","4  | nominator: (0 * 0) + (0 * 1) + (1 * 1) + (0 * 0) + (3 * 0) + (1 * 1) + (0 * 1) = 3\n","   | denominator: sqrt(0<sup>2</sup> + 0<sup>2</sup> + 1<sup>2</sup> + 0<sup>2</sup> + 3<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup>) * 2 = sqrt(12) * 2 = 3.464 * 2 = 6.928 (3 sig. fig.)\n","   | <b>cos(id = 4, query) = 3 / 6.928 = 0.433 (3 sig. fig.)</b>\n","   |\n","5  | nominator: (0 * 0) + (1 * 1) + (0 * 1) + (0 * 0) + (0 * 0) + (1 * 1) + (1 * 1) = 3\n","   | denominator: sqrt(0<sup>2</sup> + 1<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 0<sup>2</sup> + 1<sup>2</sup> + 1<sup>2</sup>) * 2 = sqrt(3) * 2 = 1.732 * 2 = 3.464 (3 sig. fig.)\n","   | <b>cos(id = 4, query) = 3 / 3.464 = 0.866 (3 sig. fig.)</b>\n","</pre>\n","\n","The closest neighbors from the above model returns ID 5, 4 and 2 in descending order, since the higher the number cosine similarity, the closer they are. The majority target level in this groups is false. Therefore, the prediction is **SPAM = false**."]},{"cell_type":"markdown","metadata":{"id":"rPNTibyA-eLX"},"source":["**2. (15%) Chapter 5, exercise 3**\n","\n","---\n","\n","**a. What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia?**\n","<pre>\n","Each parenthesis represents each feature in the order (LIFE EXP., TOP-10 INCOME, INFANT MORT., MIL. SPEND, SCHOOL YEARS)\n","The second value in each parenthesis is the query's value.\n","\n","Country ID | KNN, K = 3 using euclidean distance\n","Afghanistan| sqrt((59.61 - 67.62)<sup>2</sup> + (23.21 - 31.68)<sup>2</sup> + (74.30 - 10.00)<sup>2</sup> + (4.44 - 3.87)<sup>2</sup> + (0.40 - 12.90)<sup>2</sup>) = <b>66.535 (3 sig. fig.)</b>\n","Haiti      | sqrt((45.00 - 67.62)<sup>2</sup> + (47.67 - 31.68)<sup>2</sup> + (73.10 - 10.00)<sup>2</sup> + (0.09 - 3.87)<sup>2</sup> + (3.40 - 12.90)<sup>2</sup>) = <b>69.667 (3 sig. fig.)</b>\n","Nigeria    | sqrt((51.30 - 67.62)<sup>2</sup> + (38.23 - 31.68)<sup>2</sup> + (82.60 - 10.00)<sup>2</sup> + (1.07 - 3.87)<sup>2</sup> + (4.10 - 12.90)<sup>2</sup>) = <b>75.268 (3 sig. fig.)</b>\n","Egypt      | sqrt((70.48 - 67.62)<sup>2</sup> + (26.58 - 31.68)<sup>2</sup> + (19.60 - 10.00)<sup>2</sup> + (1.86 - 3.87)<sup>2</sup> + (5.30 - 12.90)<sup>2</sup>) = <b>13.717 (3 sig. fig.)</b>\n","Argentina  | sqrt((75.77 - 67.62)<sup>2</sup> + (32.30 - 31.68)<sup>2</sup> + (13.30 - 10.00)<sup>2</sup> + (0.76 - 3.87)<sup>2</sup> + (10.10 - 12.90)<sup>2</sup>) = <b>9.758 (3 sig. fig.)</b>\n","China      | sqrt((74.87 - 67.62)<sup>2</sup> + (29.98 - 31.68)<sup>2</sup> + (13.70 - 10.00)<sup>2</sup> + (1.95 - 3.87)<sup>2</sup> + (6.40 - 12.90)<sup>2</sup>) = <b>10.727 (3 sig. fig.)</b>\n","Brazil     | sqrt((73.12 - 67.62)<sup>2</sup> + (42.93 - 31.68)<sup>2</sup> + (14.50 - 10.00)<sup>2</sup> + (1.43 - 3.87)<sup>2</sup> + (7.20 - 12.90)<sup>2</sup>) = <b>14.680 (3 sig. fig.)</b>\n","Israel     | sqrt((81.30 - 67.62)<sup>2</sup> + (28.80 - 31.68)<sup>2</sup> + (3.60 - 10.00)<sup>2</sup> + (6.77 - 3.87)<sup>2</sup> + (12.50 - 12.90)<sup>2</sup>) = <b>15.651 (3 sig. fig.)</b>\n","U.S.A      | sqrt((78.51 - 67.62)<sup>2</sup> + (29.85 - 31.68)<sup>2</sup> + (6.30 - 10.00)<sup>2</sup> + (4.72 - 3.87)<sup>2</sup> + (13.70 - 12.90)<sup>2</sup>) = <b>11.704 (3 sig. fig.)</b>\n","Ireland    | sqrt((80.15 - 67.62)<sup>2</sup> + (27.23 - 31.68)<sup>2</sup> + (3.50 - 10.00)<sup>2</sup> + (0.60 - 3.87)<sup>2</sup> + (11.50 - 12.90)<sup>2</sup>) = <b>15.222 (3 sig. fig.)</b>\n","U.K.       | sqrt((80.09 - 67.62)<sup>2</sup> + (28.49 - 31.68)<sup>2</sup> + (4.40 - 10.00)<sup>2</sup> + (2.59 - 3.87)<sup>2</sup> + (13.00 - 12.90)<sup>2</sup>) = <b>14.096 (3 sig. fig.)</b>\n","Germany    | sqrt((80.24 - 67.62)<sup>2</sup> + (22.07 - 31.68)<sup>2</sup> + (3.50 - 10.00)<sup>2</sup> + 1.31 - 3.87)<sup>2</sup> + (12.00 - 12.90)<sup>2</sup>) = <b>17.356 (3 sig. fig.)</b>\n","Canada     | sqrt((80.99 - 67.62)<sup>2</sup> + (24.79 - 31.68)<sup>2</sup> + (4.90 - 10.00)<sup>2</sup> + (1.42 - 3.87)<sup>2</sup> + (14.20 - 12.90)<sup>2</sup>) = <b>16.122 (3 sig. fig.)</b>\n","Australia  | sqrt((82.09 - 67.62)<sup>2</sup> + (25.40 - 31.68)<sup>2</sup> + (4.20 - 10.00)<sup>2</sup> + (1.86 - 3.87)<sup>2</sup> + (11.50 - 12.90)<sup>2</sup>) = <b>16.984 (3 sig. fig.)</b>\n","Sweden     | sqrt((81.43 - 67.62)<sup>2</sup> + (22.18 - 31.68)<sup>2</sup> + (2.40 - 10.00)<sup>2</sup> + (1.27 - 3.87)<sup>2</sup> + (12.80 - 12.90)<sup>2</sup>) = <b>18.588 (3 sig. fig.)</b>\n","New Zealand| sqrt((80.67 - 67.62)<sup>2</sup> + (27.81 - 31.68)<sup>2</sup> + (4.90 - 10.00)<sup>2</sup> + (1.13 - 3.87)<sup>2</sup> + (12.30 - 12.90)<sup>2</sup>) = <b>14.804 (3 sig. fig.)</b>\n","</pre>\n","\n","The above model finds the nearest country to be Argentina, China and U.S.A in ascending order. The predicted CPI of Russia is the average of their sum, which is (2.9961 + 3.6356 + 7.1357) / 3 = **4.589** CPI.\n","\n","---\n","\n","**b. What value would a weighted k-NN prediction model return for the CPI of Russia? Use k = 16 (i.e., the full dataset) and a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query.**\n","\n","<pre>\n","\n","Country ID | weight                                        | weighted CPI\n","Afghanistan| 1 / (66.535)<sup>2</sup> = 2.26 * 10<sup>-4</sup> (3 sig. fig.)      | 1.5171 * 2.26 * 10<sup>-4</sup> = <b>3.708 * 10<sup>-4</sup> (3 sig. fig.)</b>\n","Haiti      | 1 / (69.667)<sup>2</sup> = 2.06 * 10<sup>-4</sup> (3 sig. fig.)      | 1.7999 * 2.06 * 10<sup>-4</sup> = <b>3.708 * 10<sup>-4</sup> (3 sig. fig.)</b>\n","Nigeria    | 1 / (75.268)<sup>2</sup> = 1.77 * 10<sup>-4</sup> (3 sig. fig.)      | 2.4493 * 1.77 * 10<sup>-4</sup> = <b>4.335 * 10<sup>-4</sup> (3 sig. fig.)</b>\n","Egypt      | 1 / (13.717)<sup>2</sup> = 0.00531 (3 sig. fig.)          | 2.8622 * 0.00531 = <b>0.0152 (3 sig. fig.)</b>\n","Argentina  | 1 / (9.758)<sup>2</sup> = 0.0105 (3 sig. fig.)            | 2.9961 * 0.0105 = <b>0.0314 (3 sig. fig.)</b>\n","China      | 1 / (10.727)<sup>2</sup> = 0.00869 (3 sig. fig.)          | 3.6356 * 0.00869 = <b>0.0316 (3 sig. fig.)</b>\n","Brazil     | 1 / (14.680)<sup>2</sup> = 0.00464 (3 sig. fig.)          | 3.7741 * 0.00464 = <b>0.0175 (3 sig. fig.)</b>\n","Israel     | 1 / (15.651)<sup>2</sup> = 0.00408 (3 sig. fig.)          | 5.8069 * 0.00408 = <b>0.0237 (3 sig. fig.)</b>\n","U.S.A      | 1 / (11.704)<sup>2</sup> = 0.00730 (3 sig. fig.)          | 7.1357 * 0.00730 = <b>0.0521 (3 sig. fig.)</b>\n","Ireland    | 1 / (15.222)<sup>2</sup> = 0.00432 (3 sig. fig.)          | 7.5360 * 0.00432 = <b>0.0326 (3 sig. fig.)</b>\n","U.K.       | 1 / (14.096)<sup>2</sup> = 0.00503 (3 sig. fig.)          | 7.7751 * 0.00503 = <b>0.0391 (3 sig. fig.)</b>\n","Germany    | 1 / (17.356)<sup>2</sup> = 0.00332 (3 sig. fig.)          | 8.0461 * 0.00332 = <b>0.0267 (3 sig. fig.)</b>\n","Canada     | 1 / (16.122)<sup>2</sup> = 0.00385 (3 sig. fig.)          | 8.6725 * 0.00385 = <b>0.0334 (3 sig. fig.)</b>\n","Australia  | 1 / (16.984)<sup>2</sup> = 0.00347 (3 sig. fig.)          | 8.8442 * 0.00347 = <b>0.0307 (3 sig. fig.)</b>\n","Sweden     | 1 / (18.588)<sup>2</sup> = 0.00289 (3 sig. fig.)          | 9.2985 * 0.00289 = <b>0.0269 (3 sig. fig.)</b>\n","New Zealand| 1 / (14.804)<sup>2</sup> = 0.00456 (3 sig. fig.)          | 9.4627 * 0.00456 = <b>0.0431 (3 sig. fig.)</b>\n","total      | 0.0686                                         | 0.405\n","</pre>\n","\n","The weighted model predicts the CPI to be =  0.405 / 0.0686 = **5.909**.\n","\n","---\n","\n","**c. The descriptive features in this dataset are of different types. For example, some are percentages, others are measured in years, and others are measured in counts per 1,000. We should always consider normalizing our data, but it is particularly important to do this when the descriptive features are measured in different units. What value would a 3-nearest neighbor prediction model using Euclidean distance return for the CPI of Russia when the descriptive features have been normalized using range normalization?**\n","\n","<pre>\n","Range normalization equation = (current value - min value) / (max value - min value) * (high - low) + low\n","let's high = 1, low = 0\n","\n","              |  max  |  min\n","LIFE EXP.     | 82.09 | 45.00\n","TOP-10 INCOME | 47.67 | 22.07\n","INFANT MORT.  | 82.60 |  2.40\n","MIL. SPEND    |  6.77 |  0.09\n","SCHOOL YEARS  | 14.20 |  0.40\n","\n","Range normalized data\n","Country ID |  LIFE EXP.  | TOP-10 INCOME | INFANT MORT. |  MIL. SPEND  | SCHOOL YEARS |\n","Russia     | 0.6098678889|    0.375390625| 0.09476309227|  0.5658682635|  0.9057971014|\n","                                                                                      | Euclidean distance\n","Afghanistan| 0.3939067134|     0.04453125|  0.8965087282|  0.6511976048|             0|        1.275402958\n","Haiti      |            0|              1|  0.8815461347|             0|  0.2173913043|        1.474860231\n","Nigeria    | 0.1698571043|        0.63125|             1|  0.1467065868|   0.268115942|        1.288744017\n","Egypt      |  0.686977622|    0.176171875|  0.2144638404|  0.2649700599|  0.3550724638|       0.6736465289\n","Argentina  | 0.8296036668|    0.399609375|  0.1359102244|  0.1002994012|  0.7028985507|       0.5554148304\n","China      | 0.8053383661|    0.308984375|  0.1408977556|  0.2784431138|  0.4347826087|       0.5909439683\n","Brazil     | 0.7581558372|     0.81484375|   0.150872818|  0.2005988024|  0.4927536232|       0.7226917463\n","Israel     | 0.9787004583|    0.262890625| 0.01496259352|             1|  0.8768115942|       0.5868324788\n","U.S.A      | 0.9034780264|     0.30390625| 0.04862842893|  0.6931137725|  0.9637681159|         0.33615085\n","Ireland    | 0.9476947964|      0.2015625| 0.01371571072| 0.07634730539|  0.8043478261|       0.6331150278\n","U.K.       | 0.9460771097|     0.25078125| 0.02493765586|   0.374251497|  0.9130434783|        0.412564205\n","Germany    | 0.9501213265|              0| 0.01371571072|  0.1826347305|  0.8405797101|       0.6437238927\n","Canada     | 0.9703424104|        0.10625| 0.03117206983|  0.1991017964|             1|       0.5914509297\n","Australia  |            1|    0.130078125| 0.02244389027|  0.2649700599|  0.8043478261|        0.564307574\n","Sweden     | 0.9822054462|    0.004296875|             0|  0.1766467066|  0.8985507246|        0.660962784\n","New Zealand| 0.9617147479|     0.22421875| 0.03117206983|  0.1556886228|  0.8623188406|       0.5664191583\n","</pre>\n","\n","The k-nearest neighbor model where k = 3 returns U.S.A, U.K. and Argentina in ascending order. The prediction for the query is the average of the CPI = (7.1357 + 7.7751 + 2.9961) / 3 = **5.969 (3 sig. fig.)**\n","\n","---\n","\n","**d. What value would a weighted k-NN prediction model—with k = 16 (i.e., the full dataset) and using a weighting scheme of the reciprocal of the squared Euclidean distance between the neighbor and the query—return for the CPI of Russia when it is applied to the range-normalized data?**\n","\n","<pre>\n","Country ID |   weight   | weight * CPI\n","Afghanistan|0.6147593746| 0.9326514473\n","Haiti      |0.4597251565| 0.8274593092\n","Nigeria    |0.6020972945|  1.474716903\n","Egypt      | 2.203615646|  6.307188703\n","Argentina  | 3.241642042|  9.712283723\n","China      | 2.863567281|  10.41078521\n","Brazil     | 1.914669462|  7.226154016\n","Israel     | 2.903833529|  16.86227092\n","U.S.A      | 8.849761619|  63.14924398\n","Ireland    | 2.494794372|  18.80077039\n","U.K.       | 5.875122282|  45.67966325\n","Germany    | 2.413241261|  19.41718051\n","Canada     | 2.858660379|  24.79173214\n","Australia  | 3.140279046|  27.77325594\n","Sweden     |  2.28900102|  21.28427598\n","New Zealand|  3.11690906|  29.49437536\n","total      | 45.84167882|  304.1440078\n","</pre>\n","\n","The weighted model predicts the CPI to be =  304.1440078 / 45.84167882 = **6.635**.\n","\n","---\n","\n","**e. The actual 2011 CPI for Russia was 2.4488. Which of the predictions made was the most accurate? Why do you think this was?**\n","\n","The most accurate prediction was the one that is the result from (a). I think the reason, where KNN (k = 3) using euclidean distance returhing the closest result, is because some columns have a heavier weight than others. Although all columns are collected in different format (in millions, in percentage), it gives the right features a stronger effect to affect the calculation when finding the neighbors. Range normalization transform all values into the same range but it removes the weight some columns have over the others. Therefore, the normalized KNN results performed worse than the un-normalized results."]},{"cell_type":"markdown","metadata":{"id":"sVlWvdGS-eN0"},"source":["**3. (15%) Chapter 5, exercise 4**\n","\n","---\n","\n","**a. The company has decided to use a similarity-based model to implement the recommender system. Which of the following three similarity indexes do you think the system should be based on?**\n","\n","Russell-Rao should be used because this similarity indexes captures what both instances have in common.\n","\n","---\n","\n","**b. What items will the system recommend to the following customer? Assume that the recommender system uses the similarity index you chose in the first part of this question and is trained on the sample dataset listed above. Also assume that the system generates recommendations for query customers by finding the customer most similar to them in the dataset and then recommending the items that this similar customer has bought but that the query customer has not bought.**\n","\n","<pre>\n","                q                                      q\n","         | pre. | abs.                          | pre. | abs.\n","ID 1 pre.| CP=2 | PA=0                 ID 2 pre.| CP=1 | PA=1\n","     abs.| AP=1 | CA=2                      abs.| AP=2 | CA=1\n","\n","Using Russell-Rao\n","Russell-Rao(query, ID=1) = 2 / 5 = 0.4\n","Russell-Rao(query, ID=2) = 1 / 5 = 0.2\n","</pre>\n","\n","Since ID 1 is more similar to the query, item 498 will be recommended to the user of the query."]},{"cell_type":"markdown","metadata":{"id":"-KhBnXhF-eQa"},"source":["**4. (15%) Chapter 5, exercise 5**\n","\n","---\n","\n","**a. A good measure of distance between two instances with categorical features is the overlap metric (also known as the hamming distance), which simply counts the number of descriptive features that have different values. Using this measure of distance, compute the distances between the mystery animal and each of the animals in the animal dataset.**\n","\n","<pre>\n","     | BIRTH LIVE | LAYS | FEEDS OFFSPRING| WARM-BLOODED | COLD-BLOODED | LAND AND   | HAS  | HAS      | Hamming\n","     | YOUNG      | EGGS | OWN MILK       |              |              | WATER BASED| HAIR | FEATHERS | distance\n","ID 1 |      1     |   1  |        1       |       1      |       0      |      1     |   1  |     0    |    6\n","ID 2 |      0     |   0  |        0       |       0      |       1      |      0     |   0  |     0    |    1\n","ID 3 |      1     |   1  |        1       |       1      |       0      |      1     |   1  |     0    |    6\n","ID 4 |      0     |   0  |        0       |       1      |       0      |      0     |   0  |     1    |    2\n","</pre>\n","\n","---\n","\n","**b. If you used a 1-NN model, what class would be assigned to the mystery animal?**\n","\n","The hamming distance between ID 2 and the query is the smallest. Therefore, **amphibian** is assigned to the mystery animal.\n","\n","---\n","\n","**c. If you used a 4-NN model, what class would be assigned to the mystery animal? Would this be a good value for k for this dataset?**\n","\n","In this case, there are only 4 observations in the dataset. Therefore, all instances are considered. Consequently, we will take the majority as the prediction, and assigns **mammal** to the myster animal."]},{"cell_type":"markdown","metadata":{"id":"TZBdICPd-eTa"},"source":["**5. (15%) Chapter 5, exercise 6**\n","\n","---\n","\n","**a. Create a k-d tree for this dataset. Assume the following order over the features: RENT then SIZE.**\n","\n","<pre>\n","Root\n","Sorting RENT: 800 (ID = 7), 1250 (ID = 3), 1800 (ID = 2), 3800 (ID = 5), 4000 (ID = 6), 7000 (ID = 4), 9235 (ID = 1)\n","median = 3800\n","\n","First level\n","left subtree ids = 2, 3, 7\n","Sorting SIZE = 1315, 1050, 960\n","median = 1050\n","\n","right subtree ids = 1, 4, 6\n","Sorting SIZE = 2700, 2200, 1900\n","median = 2200\n","</pre>\n","\n","k-d tree\n","![K-D TREE.png](data:image/png;base64,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)\n","---\n","\n","**b. Using the k-d tree that you created in the first part of this question, find the nearest neighbor to the following query: SIZE = 1,000, RENT = 2,200.**\n","\n","Based on the tree, since the rent is less than 3800, the query will move to the left subtree on the first level. Then, because the size of the queryt is less than 1050, it will move to the left tree node. As a result, the nearest neighbor of the query is ID 7."]},{"cell_type":"markdown","metadata":{"id":"nkcMVRfc-eW0"},"source":["**6. (25%, coding assignment) Could you implement your own KNN function from scratch (without calling any existing classifier packages)? Your own KNN function must have following parameters to tune: n_neighbors, weights. Can you compare your own classifier with sklearn neighbors.KNeighborsClassifier in terms performance, complexity, etc. Data usage: datasets.load_iris() from sklearn.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGtI1nQeYea6"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","\n","class CustomKNN:\n","\n","  def __init__(self, n_neighbors=5, weight='uniform', power=2, distance='minkowski'):\n","    \n","    if weight not in ['uniform', 'distance']:\n","      raise IOError('Unrecognized weight type')\n","    if not isinstance(power, int):\n","      raise IOError('power should be an integer')\n","    if distance not in ['minkowski', 'euclidean', 'manhattan', 'cosine']:\n","      raise IOError('Distance is not recognized')\n","\n","    self._n_neighbors = n_neighbors\n","    self._weight = weight\n","    self._distance = distance\n","    if distance == 'manhattan':\n","      self._power = 1\n","    elif distance == 'euclidean':\n","      self._power = 2\n","    else:\n","      self._power = power\n","\n","  # Showing the parameters used in this classifier\n","  def get_params(self):\n","    params = {\n","        'n_neighbors': self._n_neighbors,\n","        'weight': self._weight,\n","        'power': self._power,\n","        'distance': self._distance\n","    }\n","    return params\n","\n","  def euclidean_distance(self, query, data):\n","    ed = sum([(query[i] - data[i]) ** 2 for i in range(len(query))])\n","    ed = math.sqrt(ed)\n","    return ed\n","\n","  def manhattan_distance(self, query, data):\n","    md = sum([math.abs(query[i] - data[i]) for i in range(len(query))])\n","    return md\n","\n","  def minkowski_distance(self, query, data):\n","    if self._power == 1:\n","      return self.manhattan_distance(query, data)\n","    elif self._power == 2:\n","      return self.euclidean_distance(query, data)\n","    md = [math.pow(query[i] - data[i], self._power) for i in range(len(query))]\n","    md = sum(md)\n","    md = math.pow(md, 1 / self._power)\n","    return md\n","\n","  def cosine_similarity(self, query, data):\n","    cs = sum([query[i] * data[i] for i in range(len(query))])\n","    deno_q = math.sqrt(sum([q ** 2 for q in query]))\n","    deno_d = math.sqrt(sum([d ** 2 for d in data]))\n","    cs = cs / (deno_q * deno_d)\n","    return cs\n","\n","  def find_neighbors(self, query, dataset):\n","    distances = []\n","    distance_function = self.cosine_similarity if self._distance == 'cosine' else self.minkowski_distance\n","    for data in dataset:\n","      dist = distance_function(query, data)\n","      distances.append((data, dist))\n","    distances.sort(key=lambda t: t[1])\n","\n","    neighbors = []\n","    for i in range(self._n_neighbors):\n","      neighbors.append(distances[i][0])\n","    return neighbors\n","\n","  # Implemented to find the indices from the descriptive features \n","  # to find the targets\n","  def compare_sublist(self, des_fea, nei_fea):\n","    nei_idx = []\n","    for des in des_fea:\n","      # all neighbors are removed from the list, stop searching\n","      if nei_fea is None:\n","        break\n","\n","      rmb = None\n","      for nei in nei_fea:\n","        if all([des[i] == nei[i] for i in range(len(nei))]):\n","          # Remember the neighbor index that is found\n","          rmb = nei_fea.index(nei)\n","          nei_idx.append(des_fea.index(des))\n","          break\n","      # Pop the searched neighbor to reduce iterations\n","      if rmb:\n","        nei_fea.pop(rmb)\n","\n","    return nei_idx\n","\n","  def flatten(self, lst):\n","    res = []\n","    for it in lst:\n","        if isinstance(it, list):\n","            res.extend(self.flatten(it))\n","        else:\n","            res.append(it)\n","    return res\n","\n","  # Simple check to make sure all values in the descriptive features are numerical\n","  def validate_inputs(self, des_fea, queries):\n","    flattened = self.flatten(des_fea)\n","    return not any([isinstance(v, str) for v in flattened])\n","\n","  # Improved ChatGPT suggestion\n","  # Prompt: can you suggest a way to convert any iterable that is not a list type into a list in Python?\n","  def to_list(self, it):\n","    if isinstance(it, list):\n","        return it\n","    elif isinstance(it, tuple) or isinstance(it, set):\n","        return list(it)\n","    elif isinstance(it, dict):\n","        return list(it.values())\n","    elif isinstance(it, pd.DataFrame):\n","        return it.values.tolist()\n","    elif isinstance(it, np.ndarray):\n","        return it.tolist()\n","    else:\n","        raise TypeError(\"Object is not iterable\")\n","\n","  def predict(self, queries, descriptives, targets):\n","    queries = self.to_list(queries)\n","    descriptives = self.to_list(descriptives)\n","    if not self.validate_inputs(descriptives, queries):\n","      raise IOError('Descriptive features must be numerical')\n","\n","    targets = self.to_list(targets)\n","    target_type = 'c' if len(np.unique(targets)) <= 5 else 'r'  # check what kind of prediction to make\n","\n","    predictions = []\n","    for query in queries:\n","      neighbors = self.find_neighbors(query, descriptives)\n","      neighbors_idx = self.compare_sublist(descriptives, neighbors)\n","\n","      outputs = [targets[idx] for idx in neighbors_idx]\n","      if target_type == 'c':\n","        predictions.append(max(set(outputs), key=outputs.count))\n","      else:\n","        predictions.append(sum(outputs) / len(outputs))\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8YqNRZWN0mk"},"outputs":[],"source":["from sklearn import neighbors, datasets\n","\n","iris = datasets.load_iris()\n","\n","X = iris.data[:, :2]\n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n","\n","# print(X_train)"]},{"cell_type":"markdown","metadata":{"id":"86deAJiDBcEp"},"source":["The following sections will be comparing the complexity and performance of the custom KNN classifier and the KNN classifier from Scikit learn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679015150674,"user":{"displayName":"hon lam chung","userId":"11702692533387331032"},"user_tz":420},"id":"nLiisNJYN7f4","outputId":"706e55fb-1dae-4e1e-a7c7-c0b64e8a7050"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameters\n","{'n_neighbors': 5, 'weight': 'uniform', 'power': 2, 'distance': 'minkowski'}\n","Total execution time: 0.032500267028808594\n","Accuracy score: 0.7631578947368421\n"]}],"source":["import time\n","from sklearn.metrics import accuracy_score\n","cknn = CustomKNN()\n","\n","print(\"Parameters\")\n","print(cknn.get_params())\n","\n","start_time = time.time()\n","y_pred = cknn.predict(X_test, X_train, y_train)\n","end_time = time.time()\n","print(\"Total execution time: {}\".format(end_time - start_time))\n","print(\"Accuracy score: {}\".format(accuracy_score(y_pred, y_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1679015363064,"user":{"displayName":"hon lam chung","userId":"11702692533387331032"},"user_tz":420},"id":"LSydo4d7h-nr","outputId":"3c86d872-b2e1-4017-c61f-d6f73573a575"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameters\n","{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n","Total execution time: 0.0033164024353027344\n","Accuracy score: 0.7631578947368421\n","\n","Brute force\n","Parameters\n","{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n","Total execution time: 0.09224963188171387\n","Accuracy score: 0.7631578947368421\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier()\n","\n","print(\"Parameters\")\n","print(knn.get_params())\n","\n","knn.fit(X_train, y_train)\n","\n","start_time = time.time()\n","y_pred = knn.predict(X_test)\n","end_time = time.time()\n","print(\"Total execution time: {}\".format(end_time - start_time))\n","print(\"Accuracy score: {}\".format(accuracy_score(y_pred, y_test)))\n","\n","\n","\n","print(\"\\nBrute force\")\n","knn_br = KNeighborsClassifier(algorithm='brute')\n","\n","print(\"Parameters\")\n","print(knn.get_params())\n","\n","knn_br.fit(X_train, y_train)\n","\n","start_time = time.time()\n","y_pred = knn_br.predict(X_test)\n","end_time = time.time()\n","print(\"Total execution time: {}\".format(end_time - start_time))\n","print(\"Accuracy score: {}\".format(accuracy_score(y_pred, y_test)))\n"]},{"cell_type":"markdown","metadata":{"id":"uBA6wddBF5kL"},"source":["For the accuracy performance, under the same parameters, the custom KNN classifer performs as well as the scikit learn KNN classifier. Since the custom KNN modifier uses a brute force approach to find the neighbors, the accuracy of the custom classifier should, in most cases, perform the same as the scikit learn model.\n","\n","For the custom KNN classifier, it is using brute force to find the neighbors. The first scikit learn KNN classifier uses a automatic algorithm selector to find neighbors. The execution time on the prediction is 10 times faster than the custom KNN classifers. However, for the second KNN classifier who I specified the algorithm to be 'brute', the execution time is almost 3 times slower than the custom KNN classifier. The complexity for the custom KNN classifier is O(n * k * d * q), where n is the number of observations, d is the number of features, q is the number of queries and k is the number of neighbors. This time is mostly spent on finding the neighbors per query, and when locating the indicies for finding the targets. According to the documentation, the complexity of scikit learn KNN classifier is O(n * d). This is the complexity spent on training. In comparison, the scikit learn KNN model will outpeform the custom KNN model in most cases. I think the algorithm it chooses is a big factor of the time complexity.\n","\n","For the memory complexity, the custom KNN classifier does not store any datasets. Therefore, the memory complexity is O(1). For the scikit learn KNN classifier, since it stores the dataset into the classifier, the complexity is O(n * d).\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPNiZdEeli6SZAcOaztoht5","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
